{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task: Predict Customers who will default on a loan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORT NECESSARY LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import  GradientBoostingClassifier,RandomForestClassifier\n",
    "import lightgbm as lgbm\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "from sklearn.linear_model import  LinearRegression, Ridge\n",
    "import os, gc, warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### READING DATASETS INTO PANDA'S DATAFRAME...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train = pd.read_csv('Train (3).csv')\n",
    "Test = pd.read_csv('Test (3).csv')\n",
    "submission = pd.read_csv('SampleSubmission (1).csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DEFINING FUNCTIONS AND CLASSES TO BE USED..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fill_arbitary(col):\n",
    "    for i in col:\n",
    "        b = -999999\n",
    "        Train[i].fillna(b,inplace=True)\n",
    "        Test[i].fillna(b,inplace= True)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_predict(estimator,train,label,test,estimator_name):\n",
    "    mean_train = []\n",
    "    mean_test_val = []\n",
    "    test_pred = np.zeros(test.shape[0])\n",
    "    val_pred = np.zeros(train.shape[0])\n",
    "    for count, (train_index,test_index) in enumerate(skf.split(train,label)):\n",
    "        x_train,x_test = train.iloc[train_index],train.iloc[test_index]\n",
    "        y_train,y_test = label.iloc[train_index],label.iloc[test_index]\n",
    "        print(f'========================Fold{count +1}==========================')\n",
    "        estimator.fit(x_train,y_train,eval_set=[(x_test,y_test)],early_stopping_rounds=200,\n",
    "                               verbose=250)\n",
    "        train_predict = estimator.predict_proba(x_train, num_iteration = estimator.best_iteration_)[:,1]\n",
    "        test_predict = estimator.predict_proba(x_test, num_iteration = estimator.best_iteration_)[:,1]\n",
    "        val_pred[test_index] = test_predict\n",
    "        test_pred+= estimator.predict_proba(test, num_iteration = estimator.best_iteration_)[:,1]\n",
    "        \n",
    "        print('\\nValidation scores', roc_auc_score(y_test,test_predict))\n",
    "        print('\\nTraining scores', roc_auc_score(y_train,train_predict))\n",
    "        mean_train.append(roc_auc_score(y_train, train_predict))\n",
    "        mean_test_val.append(roc_auc_score(y_test,test_predict))\n",
    "    print('Average Testing ROC score for 10 folds split:',np.mean(mean_test_val))\n",
    "    print('Average Training ROC score for 10 folds split:',np.mean(mean_train))\n",
    "    print('standard Deviation for 10 folds split:',np.std(mean_test_val))\n",
    "    return val_pred, test_pred, estimator_name\n",
    "\n",
    "\n",
    "def xgb_predict(estimator,train,label,test,estimator_name):\n",
    "    mean_train = []\n",
    "    mean_test_val = []\n",
    "    test_pred = np.zeros(test.shape[0])\n",
    "    val_pred = np.zeros(train.shape[0])\n",
    "    for count, (train_index,test_index) in enumerate(skf.split(train,label)):\n",
    "        x_train,x_test = train.iloc[train_index],train.iloc[test_index]\n",
    "        y_train,y_test = label.iloc[train_index],label.iloc[test_index]\n",
    "        print(f'========================Fold{count +1}==========================')\n",
    "        estimator.fit(x_train, y_train, early_stopping_rounds = 200, eval_metric=\"auc\",\n",
    "                           eval_set=[(x_test, y_test)],verbose=250)\n",
    "        train_predict = estimator.predict_proba(x_train, ntree_limit = estimator.get_booster().best_ntree_limit)[:,1]\n",
    "        test_predict = estimator.predict_proba(x_test, ntree_limit = estimator.get_booster().best_ntree_limit)[:,1]\n",
    "        val_pred[test_index] = test_predict\n",
    "        test_pred+= estimator.predict_proba(test, ntree_limit = estimator.get_booster().best_ntree_limit)[:,1]\n",
    "        \n",
    "        print('\\nTesting scores', roc_auc_score(y_test,test_predict))\n",
    "        print('\\nTraining scores', roc_auc_score(y_train,train_predict))\n",
    "        mean_train.append(roc_auc_score(y_train, train_predict))\n",
    "        mean_test_val.append(roc_auc_score(y_test,test_predict))\n",
    "    print('Average Testing ROC score for 10 folds split:',np.mean(mean_test_val))\n",
    "    print('Average Training ROC score for 10 folds split:',np.mean(mean_train))\n",
    "    print('standard Deviation for 10 folds split:',np.std(mean_test_val))\n",
    "    return val_pred, test_pred, estimator_name\n",
    "\n",
    "def cat_predict(estimator,train,label,test,estimator_name):\n",
    "    mean_train = []\n",
    "    mean_test_val = []\n",
    "    test_pred = np.zeros(test.shape[0])\n",
    "    val_pred = np.zeros(train.shape[0])\n",
    "    for count, (train_index,test_index) in enumerate(skf.split(train,label)):\n",
    "        x_train,x_test = train.iloc[train_index],train.iloc[test_index]\n",
    "        y_train,y_test = label.iloc[train_index],label.iloc[test_index]\n",
    "        print(f'========================Fold{count +1}==========================')\n",
    "        estimator.fit(x_train,y_train,eval_set=[(x_test,y_test)],early_stopping_rounds=200,\n",
    "                           verbose=250,use_best_model=True)\n",
    "        train_predict = estimator.predict_proba(x_train)[:,1]\n",
    "        test_predict = estimator.predict_proba(x_test)[:,1]\n",
    "        val_pred[test_index] = test_predict\n",
    "        test_pred+= estimator.predict_proba(test)[:,1]\n",
    "        \n",
    "        print('\\nTesting scores', roc_auc_score(y_test,test_predict))\n",
    "        print('\\nTraining scores', roc_auc_score(y_train,train_predict))\n",
    "        mean_train.append(roc_auc_score(y_train, train_predict))\n",
    "        mean_test_val.append(roc_auc_score(y_test,test_predict))\n",
    "    print('Average Testing ROC score for 10 folds split:',np.mean(mean_test_val))\n",
    "    print('Average Training ROC score for 10 folds split:',np.mean(mean_train))\n",
    "    print('standard Deviation for 10 folds split:',np.std(mean_test_val))\n",
    "    return val_pred, test_pred, estimator_name\n",
    "\n",
    "\n",
    "def model_predict(estimator,train,label,test, estimator_name):\n",
    "    mean_train = []\n",
    "    mean_test_val = []\n",
    "    test_pred = np.zeros(test.shape[0])\n",
    "    val_pred = np.zeros(train.shape[0])\n",
    "    for count, (train_index,test_index) in enumerate(skf.split(train,label)):\n",
    "        x_train,x_test = train.iloc[train_index],train.iloc[test_index]\n",
    "        y_train,y_test = label.iloc[train_index],label.iloc[test_index]\n",
    "        print(f'========================Fold{count +1}==========================')\n",
    "        estimator.fit(x_train, y_train)\n",
    "        train_predict = estimator.predict_proba(x_train)[:,1]\n",
    "        test_predict = estimator.predict_proba(x_test)[:,1]\n",
    "        val_pred[test_index] = test_predict\n",
    "        test_pred+= estimator.predict_proba(test)[:,1]\n",
    "        \n",
    "        print('\\nValidation scores', roc_auc_score(y_test,test_predict))\n",
    "        print('\\nTraining scores', roc_auc_score(y_train,train_predict))\n",
    "        mean_train.append(roc_auc_score(y_train, train_predict))\n",
    "        mean_test_val.append(roc_auc_score(y_test,test_predict))\n",
    "    print('Average Testing ROC score for 10 folds split:',np.mean(mean_test_val))\n",
    "    print('Average Training ROC score for 10 folds split:',np.mean(mean_train))\n",
    "    print('standard Deviation for 10 folds split:',np.std(mean_test_val))\n",
    "    return val_pred, test_pred, estimator_name\n",
    "        \n",
    "def Stack(meta_estimator,Train_stack,Test_stack,target,file_name):\n",
    "    \n",
    "    prediction = meta_estimator.fit(Train_stack, target).predict(Test_stack)\n",
    "    submission['default_status'] = prediction\n",
    "    #LB: 0.845389667\n",
    "    submission.to_csv(file_name,index=False)\n",
    "        \n",
    "    \n",
    "    \n",
    "        \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TARGET (MEAN) ENCODING..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TargetEncoder(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Target encoder.\n",
    "    \n",
    "    Replaces categorical column(s) with the mean target value for\n",
    "    each category.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, cols=None):\n",
    "        \"\"\"Target encoder\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        cols : list of str\n",
    "            Columns to target encode.  Default is to target \n",
    "            encode all categorical columns in the DataFrame.\n",
    "        \"\"\"\n",
    "        if isinstance(cols, str):\n",
    "            self.cols = [cols]\n",
    "        else:\n",
    "            self.cols = cols\n",
    "        \n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fit target encoder to X and y\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : pandas DataFrame, shape [n_samples, n_columns]\n",
    "            DataFrame containing columns to encode\n",
    "        y : pandas Series, shape = [n_samples]\n",
    "            Target values.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        self : encoder\n",
    "            Returns self.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Encode all categorical cols by default\n",
    "        if self.cols is None:\n",
    "            self.cols = [col for col in X \n",
    "                         if str(X[col].dtype)=='object']\n",
    "\n",
    "        # Check columns are in X\n",
    "        for col in self.cols:\n",
    "            if col not in X:\n",
    "                raise ValueError('Column \\''+col+'\\' not in X')\n",
    "\n",
    "        # Encode each element of each column\n",
    "        self.maps = dict() #dict to store map for each column\n",
    "        for col in self.cols:\n",
    "            tmap = dict()\n",
    "            uniques = X[col].unique()\n",
    "            for unique in uniques:\n",
    "                tmap[unique] = y[X[col]==unique].mean()\n",
    "            self.maps[col] = tmap\n",
    "            \n",
    "        return self\n",
    "\n",
    "        \n",
    "    def transform(self, X, y=None):\n",
    "        \"\"\"Perform the target encoding transformation.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : pandas DataFrame, shape [n_samples, n_columns]\n",
    "            DataFrame containing columns to encode\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        pandas DataFrame\n",
    "            Input DataFrame with transformed columns\n",
    "        \"\"\"\n",
    "        Xo = X.copy()\n",
    "        for col, tmap in self.maps.items():\n",
    "            vals = np.full(X.shape[0], np.nan)\n",
    "            for val, mean_target in tmap.items():\n",
    "                vals[X[col]==val] = mean_target\n",
    "            Xo[col] = vals\n",
    "        return Xo\n",
    "            \n",
    "            \n",
    "    def fit_transform(self, X, y=None):\n",
    "        \"\"\"Fit and transform the data via target encoding.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : pandas DataFrame, shape [n_samples, n_columns]\n",
    "            DataFrame containing columns to encode\n",
    "        y : pandas Series, shape = [n_samples]\n",
    "            Target values (required!).\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pandas DataFrame\n",
    "            Input DataFrame with transformed columns\n",
    "        \"\"\"\n",
    "        return self.fit(X, y).transform(X, y)\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 56000 entries, 0 to 55999\n",
      "Data columns (total 52 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Applicant_ID    56000 non-null  object \n",
      " 1   form_field1     53471 non-null  float64\n",
      " 2   form_field2     52156 non-null  float64\n",
      " 3   form_field3     55645 non-null  float64\n",
      " 4   form_field4     55645 non-null  float64\n",
      " 5   form_field5     55645 non-null  float64\n",
      " 6   form_field6     42640 non-null  float64\n",
      " 7   form_field7     50837 non-null  float64\n",
      " 8   form_field8     42640 non-null  float64\n",
      " 9   form_field9     47992 non-null  float64\n",
      " 10  form_field10    55645 non-null  float64\n",
      " 11  form_field11    24579 non-null  float64\n",
      " 12  form_field12    46105 non-null  float64\n",
      " 13  form_field13    50111 non-null  float64\n",
      " 14  form_field14    56000 non-null  int64  \n",
      " 15  form_field15    33525 non-null  float64\n",
      " 16  form_field16    42964 non-null  float64\n",
      " 17  form_field17    44849 non-null  float64\n",
      " 18  form_field18    45598 non-null  float64\n",
      " 19  form_field19    55996 non-null  float64\n",
      " 20  form_field20    55645 non-null  float64\n",
      " 21  form_field21    40146 non-null  float64\n",
      " 22  form_field22    35600 non-null  float64\n",
      " 23  form_field23    27877 non-null  float64\n",
      " 24  form_field24    42703 non-null  float64\n",
      " 25  form_field25    50550 non-null  float64\n",
      " 26  form_field26    48562 non-null  float64\n",
      " 27  form_field27    46701 non-null  float64\n",
      " 28  form_field28    55645 non-null  float64\n",
      " 29  form_field29    55645 non-null  float64\n",
      " 30  form_field30    30491 non-null  float64\n",
      " 31  form_field31    16592 non-null  float64\n",
      " 32  form_field32    50550 non-null  float64\n",
      " 33  form_field33    54744 non-null  float64\n",
      " 34  form_field34    55645 non-null  float64\n",
      " 35  form_field35    32852 non-null  float64\n",
      " 36  form_field36    54005 non-null  float64\n",
      " 37  form_field37    50550 non-null  float64\n",
      " 38  form_field38    55645 non-null  float64\n",
      " 39  form_field39    51789 non-null  float64\n",
      " 40  form_field40    12271 non-null  float64\n",
      " 41  form_field41    17771 non-null  float64\n",
      " 42  form_field42    54677 non-null  float64\n",
      " 43  form_field43    55432 non-null  float64\n",
      " 44  form_field44    50617 non-null  float64\n",
      " 45  form_field45    24683 non-null  float64\n",
      " 46  form_field46    40096 non-null  float64\n",
      " 47  form_field47    56000 non-null  object \n",
      " 48  form_field48    35111 non-null  float64\n",
      " 49  form_field49    55645 non-null  float64\n",
      " 50  form_field50    44944 non-null  float64\n",
      " 51  default_status  56000 non-null  object \n",
      "dtypes: float64(48), int64(1), object(3)\n",
      "memory usage: 22.2+ MB\n"
     ]
    }
   ],
   "source": [
    "Train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Applicant_ID      0.000000\n",
       "form_field1       0.045161\n",
       "form_field2       0.068643\n",
       "form_field3       0.006339\n",
       "form_field4       0.006339\n",
       "form_field5       0.006339\n",
       "form_field6       0.238571\n",
       "form_field7       0.092196\n",
       "form_field8       0.238571\n",
       "form_field9       0.143000\n",
       "form_field10      0.006339\n",
       "form_field11      0.561089\n",
       "form_field12      0.176696\n",
       "form_field13      0.105161\n",
       "form_field14      0.000000\n",
       "form_field15      0.401339\n",
       "form_field16      0.232786\n",
       "form_field17      0.199125\n",
       "form_field18      0.185750\n",
       "form_field19      0.000071\n",
       "form_field20      0.006339\n",
       "form_field21      0.283107\n",
       "form_field22      0.364286\n",
       "form_field23      0.502196\n",
       "form_field24      0.237446\n",
       "form_field25      0.097321\n",
       "form_field26      0.132821\n",
       "form_field27      0.166054\n",
       "form_field28      0.006339\n",
       "form_field29      0.006339\n",
       "form_field30      0.455518\n",
       "form_field31      0.703714\n",
       "form_field32      0.097321\n",
       "form_field33      0.022429\n",
       "form_field34      0.006339\n",
       "form_field35      0.413357\n",
       "form_field36      0.035625\n",
       "form_field37      0.097321\n",
       "form_field38      0.006339\n",
       "form_field39      0.075196\n",
       "form_field40      0.780875\n",
       "form_field41      0.682661\n",
       "form_field42      0.023625\n",
       "form_field43      0.010143\n",
       "form_field44      0.096125\n",
       "form_field45      0.559232\n",
       "form_field46      0.284000\n",
       "form_field47      0.000000\n",
       "form_field48      0.373018\n",
       "form_field49      0.006339\n",
       "form_field50      0.197429\n",
       "default_status    0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#percentage of missing values each feature has..\n",
    "miss_percentage = Train.isnull().sum()/Train.shape[0]\n",
    "miss_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Applicant_ID', 'form_field47', 'default_status'], dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#which features are categorical?\n",
    "cat_col = Train.select_dtypes(include=[np.object]).columns\n",
    "cat_col\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['form_field1', 'form_field2', 'form_field3', 'form_field4',\n",
       "       'form_field5', 'form_field6', 'form_field7', 'form_field8',\n",
       "       'form_field9', 'form_field10', 'form_field11', 'form_field12',\n",
       "       'form_field13', 'form_field14', 'form_field15', 'form_field16',\n",
       "       'form_field17', 'form_field18', 'form_field19', 'form_field20',\n",
       "       'form_field21', 'form_field22', 'form_field23', 'form_field24',\n",
       "       'form_field25', 'form_field26', 'form_field27', 'form_field28',\n",
       "       'form_field29', 'form_field30', 'form_field31', 'form_field32',\n",
       "       'form_field33', 'form_field34', 'form_field35', 'form_field36',\n",
       "       'form_field37', 'form_field38', 'form_field39', 'form_field40',\n",
       "       'form_field41', 'form_field42', 'form_field43', 'form_field44',\n",
       "       'form_field45', 'form_field46', 'form_field48', 'form_field49',\n",
       "       'form_field50'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#which features are numerical?\n",
    "num_col = Train.select_dtypes(include=[np.number]).columns\n",
    "num_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x489a13408>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#countplot of form_field47 feature..\n",
    "sns.countplot(x='form_field47',data=Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x48aa2f0c8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#frequency distribution of form_field47 variable with respect to the target variable 'default_status'\n",
    "sns.countplot(x='form_field47',hue='default_status',data=Train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DATA PREPROCESSING...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "P88Zkc-kCrRD"
   },
   "outputs": [],
   "source": [
    "fill_arbitary(Train.drop([\"Applicant_ID\",\"default_status\"],axis=1))\n",
    "                        \n",
    "                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "TpKyevnkCuqy"
   },
   "outputs": [],
   "source": [
    "Train.default_status.replace({\"yes\":1,\"no\":0},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "hDfOxkVYCxa7"
   },
   "outputs": [],
   "source": [
    "te = TargetEncoder()\n",
    "a = pd.DataFrame(Train.form_field47)\n",
    "b = pd.DataFrame(Test.form_field47)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_target_encoded = te.fit(a,Train[\"default_status\"])\n",
    "Train =X_target_encoded.transform(Train)\n",
    "Test = X_target_encoded.transform(Test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oG-xrP_4rGe8"
   },
   "source": [
    "Extract training data, test data and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "3TGgiVZjDXAu"
   },
   "outputs": [],
   "source": [
    "train = Train.drop([\"Applicant_ID\",\"default_status\"],1)\n",
    "target = Train[\"default_status\"]\n",
    "\n",
    "test = Test.drop([\"Applicant_ID\"],1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits = 10,shuffle=True,random_state=199)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BUILDING MODELS..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL 1: LIGHTGBM(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================Fold1==========================\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[250]\tvalid_0's auc: 0.82723\n",
      "[500]\tvalid_0's auc: 0.830998\n",
      "[750]\tvalid_0's auc: 0.833157\n",
      "[1000]\tvalid_0's auc: 0.834379\n",
      "[1250]\tvalid_0's auc: 0.834906\n",
      "[1500]\tvalid_0's auc: 0.835241\n",
      "[1750]\tvalid_0's auc: 0.835256\n",
      "Early stopping, best iteration is:\n",
      "[1599]\tvalid_0's auc: 0.835322\n",
      "\n",
      "Validation scores 0.8353217054484172\n",
      "\n",
      "Training scores 0.8734712895727837\n",
      "========================Fold2==========================\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[250]\tvalid_0's auc: 0.828902\n",
      "[500]\tvalid_0's auc: 0.833391\n",
      "[750]\tvalid_0's auc: 0.835315\n",
      "[1000]\tvalid_0's auc: 0.836351\n",
      "[1250]\tvalid_0's auc: 0.836793\n",
      "[1500]\tvalid_0's auc: 0.836931\n",
      "Early stopping, best iteration is:\n",
      "[1503]\tvalid_0's auc: 0.836946\n",
      "\n",
      "Validation scores 0.836946415109179\n",
      "\n",
      "Training scores 0.8717164205500751\n",
      "========================Fold3==========================\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[250]\tvalid_0's auc: 0.829751\n",
      "[500]\tvalid_0's auc: 0.835324\n",
      "[750]\tvalid_0's auc: 0.838461\n",
      "[1000]\tvalid_0's auc: 0.84049\n",
      "[1250]\tvalid_0's auc: 0.841705\n",
      "[1500]\tvalid_0's auc: 0.842477\n",
      "[1750]\tvalid_0's auc: 0.842959\n",
      "[2000]\tvalid_0's auc: 0.843129\n",
      "Early stopping, best iteration is:\n",
      "[1929]\tvalid_0's auc: 0.843285\n",
      "\n",
      "Validation scores 0.8432851974289575\n",
      "\n",
      "Training scores 0.8783024868457998\n",
      "========================Fold4==========================\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[250]\tvalid_0's auc: 0.837237\n",
      "[500]\tvalid_0's auc: 0.842506\n",
      "[750]\tvalid_0's auc: 0.845092\n",
      "[1000]\tvalid_0's auc: 0.84645\n",
      "[1250]\tvalid_0's auc: 0.847457\n",
      "[1500]\tvalid_0's auc: 0.847967\n",
      "[1750]\tvalid_0's auc: 0.84827\n",
      "[2000]\tvalid_0's auc: 0.84847\n",
      "Early stopping, best iteration is:\n",
      "[2015]\tvalid_0's auc: 0.8485\n",
      "\n",
      "Validation scores 0.8485003084706187\n",
      "\n",
      "Training scores 0.8792009745146866\n",
      "========================Fold5==========================\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[250]\tvalid_0's auc: 0.829501\n",
      "[500]\tvalid_0's auc: 0.834701\n",
      "[750]\tvalid_0's auc: 0.837866\n",
      "[1000]\tvalid_0's auc: 0.83956\n",
      "[1250]\tvalid_0's auc: 0.840533\n",
      "[1500]\tvalid_0's auc: 0.841154\n",
      "[1750]\tvalid_0's auc: 0.841474\n",
      "Early stopping, best iteration is:\n",
      "[1758]\tvalid_0's auc: 0.84151\n",
      "\n",
      "Validation scores 0.8415097450671866\n",
      "\n",
      "Training scores 0.8753483254493055\n",
      "========================Fold6==========================\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[250]\tvalid_0's auc: 0.838583\n",
      "[500]\tvalid_0's auc: 0.842884\n",
      "[750]\tvalid_0's auc: 0.844974\n",
      "[1000]\tvalid_0's auc: 0.845949\n",
      "[1250]\tvalid_0's auc: 0.846515\n",
      "[1500]\tvalid_0's auc: 0.846812\n",
      "[1750]\tvalid_0's auc: 0.846903\n",
      "Early stopping, best iteration is:\n",
      "[1590]\tvalid_0's auc: 0.846947\n",
      "\n",
      "Validation scores 0.8469472225976482\n",
      "\n",
      "Training scores 0.872250299401761\n",
      "========================Fold7==========================\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[250]\tvalid_0's auc: 0.819679\n",
      "[500]\tvalid_0's auc: 0.82669\n",
      "[750]\tvalid_0's auc: 0.830665\n",
      "[1000]\tvalid_0's auc: 0.832939\n",
      "[1250]\tvalid_0's auc: 0.834629\n",
      "[1500]\tvalid_0's auc: 0.835605\n",
      "[1750]\tvalid_0's auc: 0.836341\n",
      "[2000]\tvalid_0's auc: 0.836797\n",
      "[2250]\tvalid_0's auc: 0.837076\n",
      "[2500]\tvalid_0's auc: 0.83731\n",
      "[2750]\tvalid_0's auc: 0.837475\n",
      "[3000]\tvalid_0's auc: 0.837538\n",
      "Early stopping, best iteration is:\n",
      "[2956]\tvalid_0's auc: 0.837591\n",
      "\n",
      "Validation scores 0.8375912975002138\n",
      "\n",
      "Training scores 0.8940637470986432\n",
      "========================Fold8==========================\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[250]\tvalid_0's auc: 0.823255\n",
      "[500]\tvalid_0's auc: 0.827942\n",
      "[750]\tvalid_0's auc: 0.830684\n",
      "[1000]\tvalid_0's auc: 0.832466\n",
      "[1250]\tvalid_0's auc: 0.833412\n",
      "[1500]\tvalid_0's auc: 0.834054\n",
      "[1750]\tvalid_0's auc: 0.834219\n",
      "[2000]\tvalid_0's auc: 0.834417\n",
      "[2250]\tvalid_0's auc: 0.834548\n",
      "Early stopping, best iteration is:\n",
      "[2215]\tvalid_0's auc: 0.834589\n",
      "\n",
      "Validation scores 0.8345893060562516\n",
      "\n",
      "Training scores 0.8830818562768042\n",
      "========================Fold9==========================\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[250]\tvalid_0's auc: 0.83134\n",
      "[500]\tvalid_0's auc: 0.836733\n",
      "[750]\tvalid_0's auc: 0.839162\n",
      "[1000]\tvalid_0's auc: 0.840395\n",
      "[1250]\tvalid_0's auc: 0.841097\n",
      "[1500]\tvalid_0's auc: 0.84136\n",
      "[1750]\tvalid_0's auc: 0.841683\n",
      "[2000]\tvalid_0's auc: 0.841704\n",
      "Early stopping, best iteration is:\n",
      "[1811]\tvalid_0's auc: 0.841801\n",
      "\n",
      "Validation scores 0.8418007052800849\n",
      "\n",
      "Training scores 0.8764075133520677\n",
      "========================Fold10==========================\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[250]\tvalid_0's auc: 0.832638\n",
      "[500]\tvalid_0's auc: 0.838365\n",
      "[750]\tvalid_0's auc: 0.841279\n",
      "[1000]\tvalid_0's auc: 0.842937\n",
      "[1250]\tvalid_0's auc: 0.843775\n",
      "[1500]\tvalid_0's auc: 0.844284\n",
      "[1750]\tvalid_0's auc: 0.844709\n",
      "[2000]\tvalid_0's auc: 0.844717\n",
      "[2250]\tvalid_0's auc: 0.844821\n",
      "Early stopping, best iteration is:\n",
      "[2102]\tvalid_0's auc: 0.844841\n",
      "\n",
      "Validation scores 0.844841311980935\n",
      "\n",
      "Training scores 0.8809982129787193\n",
      "Average Testing ROC score for 10 folds split: 0.8411333214939493\n",
      "Average Training ROC score for 10 folds split: 0.8784841126040647\n",
      "standard Deviation for 10 folds split: 0.00462294214359512\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lgb_model = lgbm.LGBMClassifier(random_state=34, n_estimators=5000,colsample_bytree=0.9,min_child_samples=10,\n",
    "    subsample=0.7,subsample_freq=2,num_leaves=120,reg_lambda=2,reg_alpha=5 ,metric='auc', learning_rate=0.008,\n",
    "    max_depth=5)\n",
    "LGB1__train, LGB1_test, LGB1_name =lgb_predict(lgb_model,train, target, test,'lightgbm(1)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL 2: CATBOOST(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================Fold1==========================\n",
      "Learning rate set to 0.041434\n",
      "0:\ttest: 0.7957900\tbest: 0.7957900 (0)\ttotal: 588ms\tremaining: 48m 58s\n",
      "250:\ttest: 0.8347772\tbest: 0.8347772 (250)\ttotal: 19.6s\tremaining: 6m 10s\n",
      "500:\ttest: 0.8358065\tbest: 0.8358472 (498)\ttotal: 35.8s\tremaining: 5m 21s\n",
      "750:\ttest: 0.8352850\tbest: 0.8359142 (602)\ttotal: 51.9s\tremaining: 4m 53s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.8359141553\n",
      "bestIteration = 602\n",
      "\n",
      "Shrink model to first 603 iterations.\n",
      "\n",
      "Testing scores 0.8359141553087905\n",
      "\n",
      "Training scores 0.8763953900831206\n",
      "========================Fold2==========================\n",
      "Learning rate set to 0.041434\n",
      "0:\ttest: 0.7994374\tbest: 0.7994374 (0)\ttotal: 142ms\tremaining: 11m 47s\n",
      "250:\ttest: 0.8365111\tbest: 0.8365257 (245)\ttotal: 18.6s\tremaining: 5m 52s\n",
      "500:\ttest: 0.8377243\tbest: 0.8377917 (392)\ttotal: 35.1s\tremaining: 5m 14s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.8377917126\n",
      "bestIteration = 392\n",
      "\n",
      "Shrink model to first 393 iterations.\n",
      "\n",
      "Testing scores 0.8377917125664393\n",
      "\n",
      "Training scores 0.8631831159960606\n",
      "========================Fold3==========================\n",
      "Learning rate set to 0.041434\n",
      "0:\ttest: 0.7923186\tbest: 0.7923186 (0)\ttotal: 126ms\tremaining: 10m 31s\n",
      "250:\ttest: 0.8394683\tbest: 0.8394791 (249)\ttotal: 22.6s\tremaining: 7m 6s\n",
      "500:\ttest: 0.8419306\tbest: 0.8421403 (428)\ttotal: 39.1s\tremaining: 5m 51s\n",
      "750:\ttest: 0.8425522\tbest: 0.8427324 (719)\ttotal: 54.9s\tremaining: 5m 10s\n",
      "1000:\ttest: 0.8431148\tbest: 0.8432259 (985)\ttotal: 1m 10s\tremaining: 4m 41s\n",
      "1250:\ttest: 0.8429608\tbest: 0.8433045 (1111)\ttotal: 1m 26s\tremaining: 4m 18s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.8433045146\n",
      "bestIteration = 1111\n",
      "\n",
      "Shrink model to first 1112 iterations.\n",
      "\n",
      "Testing scores 0.8433045145714206\n",
      "\n",
      "Training scores 0.900058417509633\n",
      "========================Fold4==========================\n",
      "Learning rate set to 0.041434\n",
      "0:\ttest: 0.8025848\tbest: 0.8025848 (0)\ttotal: 125ms\tremaining: 10m 25s\n",
      "250:\ttest: 0.8464474\tbest: 0.8466297 (240)\ttotal: 18s\tremaining: 5m 40s\n",
      "500:\ttest: 0.8484563\tbest: 0.8485947 (470)\ttotal: 33.7s\tremaining: 5m 2s\n",
      "750:\ttest: 0.8486172\tbest: 0.8487197 (601)\ttotal: 49.5s\tremaining: 4m 40s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.848719696\n",
      "bestIteration = 601\n",
      "\n",
      "Shrink model to first 602 iterations.\n",
      "\n",
      "Testing scores 0.8487196960171676\n",
      "\n",
      "Training scores 0.8751846132012571\n",
      "========================Fold5==========================\n",
      "Learning rate set to 0.041434\n",
      "0:\ttest: 0.7958699\tbest: 0.7958699 (0)\ttotal: 138ms\tremaining: 11m 28s\n",
      "250:\ttest: 0.8392001\tbest: 0.8392417 (246)\ttotal: 18.2s\tremaining: 5m 43s\n",
      "500:\ttest: 0.8408230\tbest: 0.8408354 (497)\ttotal: 35s\tremaining: 5m 13s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.8410285413\n",
      "bestIteration = 544\n",
      "\n",
      "Shrink model to first 545 iterations.\n",
      "\n",
      "Testing scores 0.8410285412504641\n",
      "\n",
      "Training scores 0.8721788034493902\n",
      "========================Fold6==========================\n",
      "Learning rate set to 0.041434\n",
      "0:\ttest: 0.8065865\tbest: 0.8065865 (0)\ttotal: 73.9ms\tremaining: 6m 9s\n",
      "250:\ttest: 0.8462091\tbest: 0.8462091 (250)\ttotal: 17.2s\tremaining: 5m 25s\n",
      "500:\ttest: 0.8473136\tbest: 0.8473189 (497)\ttotal: 34.2s\tremaining: 5m 7s\n",
      "750:\ttest: 0.8480279\tbest: 0.8480572 (747)\ttotal: 51.2s\tremaining: 4m 49s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.8480999914\n",
      "bestIteration = 763\n",
      "\n",
      "Shrink model to first 764 iterations.\n",
      "\n",
      "Testing scores 0.8480999914494789\n",
      "\n",
      "Training scores 0.8840103162201738\n",
      "========================Fold7==========================\n",
      "Learning rate set to 0.041434\n",
      "0:\ttest: 0.7928042\tbest: 0.7928042 (0)\ttotal: 140ms\tremaining: 11m 37s\n",
      "250:\ttest: 0.8338937\tbest: 0.8338937 (250)\ttotal: 19.3s\tremaining: 6m 5s\n",
      "500:\ttest: 0.8365109\tbest: 0.8365109 (500)\ttotal: 36.5s\tremaining: 5m 27s\n",
      "750:\ttest: 0.8375939\tbest: 0.8376115 (729)\ttotal: 53.4s\tremaining: 5m 1s\n",
      "1000:\ttest: 0.8383479\tbest: 0.8384001 (997)\ttotal: 1m 10s\tremaining: 4m 41s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.8384213531\n",
      "bestIteration = 1013\n",
      "\n",
      "Shrink model to first 1014 iterations.\n",
      "\n",
      "Testing scores 0.8384213531337661\n",
      "\n",
      "Training scores 0.8961539185101257\n",
      "========================Fold8==========================\n",
      "Learning rate set to 0.041434\n",
      "0:\ttest: 0.7917517\tbest: 0.7917517 (0)\ttotal: 130ms\tremaining: 10m 50s\n",
      "250:\ttest: 0.8325744\tbest: 0.8325805 (249)\ttotal: 18.6s\tremaining: 5m 51s\n",
      "500:\ttest: 0.8347108\tbest: 0.8347108 (500)\ttotal: 34.8s\tremaining: 5m 12s\n",
      "750:\ttest: 0.8349022\tbest: 0.8350280 (647)\ttotal: 53s\tremaining: 4m 59s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.8350447592\n",
      "bestIteration = 766\n",
      "\n",
      "Shrink model to first 767 iterations.\n",
      "\n",
      "Testing scores 0.8350447592200823\n",
      "\n",
      "Training scores 0.8849141390018445\n",
      "========================Fold9==========================\n",
      "Learning rate set to 0.041434\n",
      "0:\ttest: 0.7942406\tbest: 0.7942406 (0)\ttotal: 123ms\tremaining: 10m 14s\n",
      "250:\ttest: 0.8405447\tbest: 0.8405631 (248)\ttotal: 19.3s\tremaining: 6m 5s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.8410192635\n",
      "bestIteration = 298\n",
      "\n",
      "Shrink model to first 299 iterations.\n",
      "\n",
      "Testing scores 0.8410192634967218\n",
      "\n",
      "Training scores 0.8553590470777584\n",
      "========================Fold10==========================\n",
      "Learning rate set to 0.041434\n",
      "0:\ttest: 0.7980195\tbest: 0.7980195 (0)\ttotal: 216ms\tremaining: 17m 57s\n",
      "250:\ttest: 0.8420854\tbest: 0.8420982 (249)\ttotal: 23s\tremaining: 7m 15s\n",
      "500:\ttest: 0.8440962\tbest: 0.8441942 (468)\ttotal: 42.3s\tremaining: 6m 19s\n",
      "750:\ttest: 0.8448108\tbest: 0.8448601 (744)\ttotal: 1m 1s\tremaining: 5m 49s\n",
      "1000:\ttest: 0.8450213\tbest: 0.8451113 (976)\ttotal: 1m 22s\tremaining: 5m 30s\n",
      "1250:\ttest: 0.8451435\tbest: 0.8453874 (1219)\ttotal: 1m 43s\tremaining: 5m 9s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.845387442\n",
      "bestIteration = 1219\n",
      "\n",
      "Shrink model to first 1220 iterations.\n",
      "\n",
      "Testing scores 0.8453874420426367\n",
      "\n",
      "Training scores 0.9045995643639739\n",
      "Average Testing ROC score for 10 folds split: 0.8414731429056967\n",
      "Average Training ROC score for 10 folds split: 0.8812037325413338\n",
      "standard Deviation for 10 folds split: 0.004589115391311108\n"
     ]
    }
   ],
   "source": [
    "catboost =  CatBoostClassifier(random_seed=34,use_best_model=True,\n",
    "                          n_estimators=5000,silent=True,eval_metric='AUC')\n",
    "\n",
    "\n",
    "cat1_train, cat1_test, cat1_name = cat_predict(catboost,train, target, test,  'catboost(1)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL 3: CATBOOST(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================Fold1==========================\n",
      "0:\ttest: 0.7935997\tbest: 0.7935997 (0)\ttotal: 257ms\tremaining: 34m 14s\n",
      "250:\ttest: 0.8272039\tbest: 0.8272039 (250)\ttotal: 22.3s\tremaining: 11m 28s\n",
      "500:\ttest: 0.8303926\tbest: 0.8303926 (500)\ttotal: 39.4s\tremaining: 9m 50s\n",
      "750:\ttest: 0.8318572\tbest: 0.8318660 (748)\ttotal: 56.1s\tremaining: 9m 1s\n",
      "1000:\ttest: 0.8329971\tbest: 0.8329971 (1000)\ttotal: 1m 13s\tremaining: 8m 31s\n",
      "1250:\ttest: 0.8337541\tbest: 0.8337541 (1250)\ttotal: 1m 30s\tremaining: 8m 6s\n",
      "1500:\ttest: 0.8343948\tbest: 0.8344043 (1499)\ttotal: 1m 47s\tremaining: 7m 43s\n",
      "1750:\ttest: 0.8347812\tbest: 0.8347839 (1748)\ttotal: 2m 3s\tremaining: 7m 22s\n",
      "2000:\ttest: 0.8351992\tbest: 0.8351994 (1999)\ttotal: 2m 17s\tremaining: 6m 52s\n",
      "2250:\ttest: 0.8354635\tbest: 0.8354649 (2247)\ttotal: 2m 31s\tremaining: 6m 26s\n",
      "2500:\ttest: 0.8356544\tbest: 0.8356625 (2497)\ttotal: 2m 45s\tremaining: 6m 3s\n",
      "2750:\ttest: 0.8357736\tbest: 0.8357736 (2750)\ttotal: 2m 59s\tremaining: 5m 41s\n",
      "3000:\ttest: 0.8358717\tbest: 0.8358779 (2994)\ttotal: 3m 13s\tremaining: 5m 21s\n",
      "3250:\ttest: 0.8358848\tbest: 0.8359074 (3113)\ttotal: 3m 27s\tremaining: 5m 2s\n",
      "3500:\ttest: 0.8358917\tbest: 0.8359373 (3347)\ttotal: 3m 40s\tremaining: 4m 43s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.8359372669\n",
      "bestIteration = 3347\n",
      "\n",
      "Shrink model to first 3348 iterations.\n",
      "\n",
      "Testing scores 0.8359372668899521\n",
      "\n",
      "Training scores 0.8689309813719278\n",
      "========================Fold2==========================\n",
      "0:\ttest: 0.8007765\tbest: 0.8007765 (0)\ttotal: 113ms\tremaining: 15m 1s\n",
      "250:\ttest: 0.8282183\tbest: 0.8282183 (250)\ttotal: 16.7s\tremaining: 8m 35s\n",
      "500:\ttest: 0.8317887\tbest: 0.8317887 (500)\ttotal: 33s\tremaining: 8m 13s\n",
      "750:\ttest: 0.8334728\tbest: 0.8334728 (750)\ttotal: 47s\tremaining: 7m 33s\n",
      "1000:\ttest: 0.8344152\tbest: 0.8344152 (1000)\ttotal: 1m\tremaining: 7m 6s\n",
      "1250:\ttest: 0.8352087\tbest: 0.8352087 (1250)\ttotal: 1m 15s\tremaining: 6m 44s\n",
      "1500:\ttest: 0.8357553\tbest: 0.8357615 (1498)\ttotal: 1m 29s\tremaining: 6m 25s\n",
      "1750:\ttest: 0.8361741\tbest: 0.8361741 (1750)\ttotal: 1m 42s\tremaining: 6m 7s\n",
      "2000:\ttest: 0.8364992\tbest: 0.8365006 (1998)\ttotal: 1m 56s\tremaining: 5m 49s\n",
      "2250:\ttest: 0.8368683\tbest: 0.8369021 (2239)\ttotal: 2m 10s\tremaining: 5m 32s\n",
      "2500:\ttest: 0.8370675\tbest: 0.8370754 (2495)\ttotal: 2m 24s\tremaining: 5m 17s\n",
      "2750:\ttest: 0.8371023\tbest: 0.8371411 (2579)\ttotal: 2m 38s\tremaining: 5m 1s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.8371411388\n",
      "bestIteration = 2579\n",
      "\n",
      "Shrink model to first 2580 iterations.\n",
      "\n",
      "Testing scores 0.8371411388041896\n",
      "\n",
      "Training scores 0.8624021353870702\n",
      "========================Fold3==========================\n",
      "0:\ttest: 0.7923715\tbest: 0.7923715 (0)\ttotal: 114ms\tremaining: 15m 10s\n",
      "250:\ttest: 0.8284042\tbest: 0.8284042 (250)\ttotal: 16.8s\tremaining: 8m 39s\n",
      "500:\ttest: 0.8333500\tbest: 0.8333500 (500)\ttotal: 30.8s\tremaining: 7m 41s\n",
      "750:\ttest: 0.8358622\tbest: 0.8358634 (749)\ttotal: 44.8s\tremaining: 7m 12s\n",
      "1000:\ttest: 0.8375854\tbest: 0.8375854 (1000)\ttotal: 58.6s\tremaining: 6m 49s\n",
      "1250:\ttest: 0.8388490\tbest: 0.8388490 (1250)\ttotal: 1m 13s\tremaining: 6m 34s\n",
      "1500:\ttest: 0.8397926\tbest: 0.8397967 (1496)\ttotal: 1m 27s\tremaining: 6m 17s\n",
      "1750:\ttest: 0.8405227\tbest: 0.8405227 (1750)\ttotal: 1m 40s\tremaining: 5m 59s\n",
      "2000:\ttest: 0.8411220\tbest: 0.8411220 (2000)\ttotal: 1m 54s\tremaining: 5m 43s\n",
      "2250:\ttest: 0.8416626\tbest: 0.8416705 (2233)\ttotal: 2m 7s\tremaining: 5m 26s\n",
      "2500:\ttest: 0.8419847\tbest: 0.8420044 (2489)\ttotal: 2m 21s\tremaining: 5m 11s\n",
      "2750:\ttest: 0.8422840\tbest: 0.8422869 (2747)\ttotal: 2m 35s\tremaining: 4m 56s\n",
      "3000:\ttest: 0.8425510\tbest: 0.8425570 (2999)\ttotal: 2m 49s\tremaining: 4m 42s\n",
      "3250:\ttest: 0.8426460\tbest: 0.8426752 (3217)\ttotal: 3m 3s\tremaining: 4m 28s\n",
      "3500:\ttest: 0.8428359\tbest: 0.8428526 (3479)\ttotal: 3m 17s\tremaining: 4m 13s\n",
      "3750:\ttest: 0.8429528\tbest: 0.8429810 (3710)\ttotal: 3m 31s\tremaining: 3m 59s\n",
      "4000:\ttest: 0.8431295\tbest: 0.8431315 (3999)\ttotal: 3m 45s\tremaining: 3m 45s\n",
      "4250:\ttest: 0.8431533\tbest: 0.8431710 (4224)\ttotal: 3m 58s\tremaining: 3m 30s\n",
      "4500:\ttest: 0.8432245\tbest: 0.8432640 (4335)\ttotal: 4m 12s\tremaining: 3m 16s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.8432639831\n",
      "bestIteration = 4335\n",
      "\n",
      "Shrink model to first 4336 iterations.\n",
      "\n",
      "Testing scores 0.8432639830671449\n",
      "\n",
      "Training scores 0.8755613508339383\n",
      "========================Fold4==========================\n",
      "0:\ttest: 0.8031946\tbest: 0.8031946 (0)\ttotal: 139ms\tremaining: 18m 28s\n",
      "250:\ttest: 0.8368970\tbest: 0.8368970 (250)\ttotal: 16s\tremaining: 8m 14s\n",
      "500:\ttest: 0.8410517\tbest: 0.8410517 (500)\ttotal: 29.5s\tremaining: 7m 22s\n",
      "750:\ttest: 0.8433049\tbest: 0.8433049 (750)\ttotal: 43.2s\tremaining: 6m 57s\n",
      "1000:\ttest: 0.8447035\tbest: 0.8447035 (1000)\ttotal: 57.1s\tremaining: 6m 39s\n",
      "1250:\ttest: 0.8456253\tbest: 0.8456276 (1247)\ttotal: 1m 10s\tremaining: 6m 22s\n",
      "1500:\ttest: 0.8463784\tbest: 0.8463784 (1500)\ttotal: 1m 24s\tremaining: 6m 5s\n",
      "1750:\ttest: 0.8468984\tbest: 0.8468996 (1749)\ttotal: 1m 38s\tremaining: 5m 49s\n",
      "2000:\ttest: 0.8472673\tbest: 0.8472673 (2000)\ttotal: 1m 51s\tremaining: 5m 34s\n",
      "2250:\ttest: 0.8476259\tbest: 0.8476283 (2247)\ttotal: 2m 5s\tremaining: 5m 19s\n",
      "2500:\ttest: 0.8480253\tbest: 0.8480253 (2500)\ttotal: 2m 18s\tremaining: 5m 5s\n",
      "2750:\ttest: 0.8483620\tbest: 0.8483675 (2749)\ttotal: 2m 32s\tremaining: 4m 51s\n",
      "3000:\ttest: 0.8485117\tbest: 0.8485519 (2928)\ttotal: 2m 46s\tremaining: 4m 37s\n",
      "3250:\ttest: 0.8486121\tbest: 0.8486428 (3239)\ttotal: 3m\tremaining: 4m 23s\n",
      "3500:\ttest: 0.8487466\tbest: 0.8487557 (3440)\ttotal: 3m 14s\tremaining: 4m 9s\n",
      "3750:\ttest: 0.8487752\tbest: 0.8488073 (3666)\ttotal: 3m 28s\tremaining: 3m 55s\n",
      "4000:\ttest: 0.8488918\tbest: 0.8489372 (3950)\ttotal: 3m 41s\tremaining: 3m 41s\n",
      "4250:\ttest: 0.8490303\tbest: 0.8490329 (4244)\ttotal: 3m 55s\tremaining: 3m 27s\n",
      "4500:\ttest: 0.8490624\tbest: 0.8490688 (4487)\ttotal: 4m 9s\tremaining: 3m 13s\n",
      "4750:\ttest: 0.8490410\tbest: 0.8490890 (4651)\ttotal: 4m 23s\tremaining: 2m 59s\n",
      "5000:\ttest: 0.8491793\tbest: 0.8491849 (4984)\ttotal: 4m 36s\tremaining: 2m 46s\n",
      "5250:\ttest: 0.8491797\tbest: 0.8491959 (5071)\ttotal: 4m 50s\tremaining: 2m 32s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.8491958981\n",
      "bestIteration = 5071\n",
      "\n",
      "Shrink model to first 5072 iterations.\n",
      "\n",
      "Testing scores 0.8491958980737876\n",
      "\n",
      "Training scores 0.8808176547836657\n",
      "========================Fold5==========================\n",
      "0:\ttest: 0.8030466\tbest: 0.8030466 (0)\ttotal: 123ms\tremaining: 16m 20s\n",
      "250:\ttest: 0.8296613\tbest: 0.8296613 (250)\ttotal: 17.4s\tremaining: 8m 57s\n",
      "500:\ttest: 0.8333960\tbest: 0.8333960 (500)\ttotal: 32.3s\tremaining: 8m 3s\n",
      "750:\ttest: 0.8354907\tbest: 0.8354907 (750)\ttotal: 46.8s\tremaining: 7m 31s\n",
      "1000:\ttest: 0.8369878\tbest: 0.8369878 (1000)\ttotal: 1m\tremaining: 7m 4s\n",
      "1250:\ttest: 0.8379635\tbest: 0.8379635 (1250)\ttotal: 1m 14s\tremaining: 6m 41s\n",
      "1500:\ttest: 0.8387671\tbest: 0.8387671 (1500)\ttotal: 1m 28s\tremaining: 6m 23s\n",
      "1750:\ttest: 0.8393704\tbest: 0.8393704 (1750)\ttotal: 1m 42s\tremaining: 6m 4s\n",
      "2000:\ttest: 0.8398205\tbest: 0.8398205 (2000)\ttotal: 1m 55s\tremaining: 5m 46s\n",
      "2250:\ttest: 0.8402369\tbest: 0.8402462 (2249)\ttotal: 2m 9s\tremaining: 5m 30s\n",
      "2500:\ttest: 0.8405887\tbest: 0.8406051 (2487)\ttotal: 2m 23s\tremaining: 5m 15s\n",
      "2750:\ttest: 0.8408443\tbest: 0.8408450 (2749)\ttotal: 2m 37s\tremaining: 4m 59s\n",
      "3000:\ttest: 0.8409740\tbest: 0.8409740 (3000)\ttotal: 2m 51s\tremaining: 4m 44s\n",
      "3250:\ttest: 0.8411193\tbest: 0.8411379 (3245)\ttotal: 3m 4s\tremaining: 4m 30s\n",
      "3500:\ttest: 0.8412717\tbest: 0.8412760 (3498)\ttotal: 3m 18s\tremaining: 4m 15s\n",
      "3750:\ttest: 0.8413950\tbest: 0.8413983 (3699)\ttotal: 3m 32s\tremaining: 4m\n",
      "4000:\ttest: 0.8415134\tbest: 0.8415425 (3929)\ttotal: 3m 46s\tremaining: 3m 46s\n",
      "4250:\ttest: 0.8414573\tbest: 0.8415932 (4065)\ttotal: 4m\tremaining: 3m 31s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.8415932227\n",
      "bestIteration = 4065\n",
      "\n",
      "Shrink model to first 4066 iterations.\n",
      "\n",
      "Testing scores 0.8415932227185463\n",
      "\n",
      "Training scores 0.8737931942673152\n",
      "========================Fold6==========================\n",
      "0:\ttest: 0.8056071\tbest: 0.8056071 (0)\ttotal: 157ms\tremaining: 20m 59s\n",
      "250:\ttest: 0.8374669\tbest: 0.8374669 (250)\ttotal: 16.9s\tremaining: 8m 42s\n",
      "500:\ttest: 0.8413797\tbest: 0.8413797 (500)\ttotal: 30.8s\tremaining: 7m 41s\n",
      "750:\ttest: 0.8429616\tbest: 0.8429616 (750)\ttotal: 44.9s\tremaining: 7m 12s\n",
      "1000:\ttest: 0.8441521\tbest: 0.8441521 (1000)\ttotal: 58.8s\tremaining: 6m 51s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250:\ttest: 0.8448992\tbest: 0.8448992 (1250)\ttotal: 1m 12s\tremaining: 6m 32s\n",
      "1500:\ttest: 0.8456053\tbest: 0.8456124 (1498)\ttotal: 1m 26s\tremaining: 6m 15s\n",
      "1750:\ttest: 0.8459984\tbest: 0.8460198 (1741)\ttotal: 1m 40s\tremaining: 5m 58s\n",
      "2000:\ttest: 0.8463268\tbest: 0.8463375 (1991)\ttotal: 1m 54s\tremaining: 5m 43s\n",
      "2250:\ttest: 0.8466954\tbest: 0.8467033 (2248)\ttotal: 2m 7s\tremaining: 5m 26s\n",
      "2500:\ttest: 0.8469639\tbest: 0.8469724 (2491)\ttotal: 2m 21s\tremaining: 5m 11s\n",
      "2750:\ttest: 0.8471631\tbest: 0.8471751 (2743)\ttotal: 2m 35s\tremaining: 4m 56s\n",
      "3000:\ttest: 0.8472765\tbest: 0.8473044 (2987)\ttotal: 2m 49s\tremaining: 4m 42s\n",
      "3250:\ttest: 0.8474268\tbest: 0.8474320 (3249)\ttotal: 3m 3s\tremaining: 4m 27s\n",
      "3500:\ttest: 0.8475876\tbest: 0.8476242 (3463)\ttotal: 3m 17s\tremaining: 4m 13s\n",
      "3750:\ttest: 0.8476557\tbest: 0.8476573 (3748)\ttotal: 3m 31s\tremaining: 3m 59s\n",
      "4000:\ttest: 0.8477914\tbest: 0.8478116 (3981)\ttotal: 3m 45s\tremaining: 3m 45s\n",
      "4250:\ttest: 0.8478154\tbest: 0.8478833 (4154)\ttotal: 3m 58s\tremaining: 3m 30s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.8478832978\n",
      "bestIteration = 4154\n",
      "\n",
      "Shrink model to first 4155 iterations.\n",
      "\n",
      "Testing scores 0.8478832977981031\n",
      "\n",
      "Training scores 0.8741566373091599\n",
      "========================Fold7==========================\n",
      "0:\ttest: 0.7905434\tbest: 0.7905434 (0)\ttotal: 117ms\tremaining: 15m 34s\n",
      "250:\ttest: 0.8214349\tbest: 0.8214349 (250)\ttotal: 16.3s\tremaining: 8m 21s\n",
      "500:\ttest: 0.8263696\tbest: 0.8263713 (499)\ttotal: 30.2s\tremaining: 7m 32s\n",
      "750:\ttest: 0.8290149\tbest: 0.8290149 (750)\ttotal: 44s\tremaining: 7m 4s\n",
      "1000:\ttest: 0.8308926\tbest: 0.8308928 (999)\ttotal: 57.8s\tremaining: 6m 43s\n",
      "1250:\ttest: 0.8322589\tbest: 0.8322589 (1250)\ttotal: 1m 11s\tremaining: 6m 24s\n",
      "1500:\ttest: 0.8333412\tbest: 0.8333412 (1500)\ttotal: 1m 24s\tremaining: 6m 7s\n",
      "1750:\ttest: 0.8343021\tbest: 0.8343021 (1750)\ttotal: 1m 38s\tremaining: 5m 51s\n",
      "2000:\ttest: 0.8350217\tbest: 0.8350249 (1999)\ttotal: 1m 52s\tremaining: 5m 36s\n",
      "2250:\ttest: 0.8354794\tbest: 0.8355000 (2236)\ttotal: 2m 6s\tremaining: 5m 21s\n",
      "2500:\ttest: 0.8360362\tbest: 0.8360369 (2496)\ttotal: 2m 19s\tremaining: 5m 7s\n",
      "2750:\ttest: 0.8363654\tbest: 0.8363685 (2748)\ttotal: 2m 33s\tremaining: 4m 53s\n",
      "3000:\ttest: 0.8367554\tbest: 0.8367554 (3000)\ttotal: 2m 47s\tremaining: 4m 38s\n",
      "3250:\ttest: 0.8370209\tbest: 0.8370259 (3243)\ttotal: 3m\tremaining: 4m 24s\n",
      "3500:\ttest: 0.8372943\tbest: 0.8372962 (3498)\ttotal: 3m 14s\tremaining: 4m 10s\n",
      "3750:\ttest: 0.8375430\tbest: 0.8375449 (3739)\ttotal: 3m 28s\tremaining: 3m 56s\n",
      "4000:\ttest: 0.8377530\tbest: 0.8377835 (3976)\ttotal: 3m 42s\tremaining: 3m 42s\n",
      "4250:\ttest: 0.8378699\tbest: 0.8378749 (4247)\ttotal: 3m 56s\tremaining: 3m 28s\n",
      "4500:\ttest: 0.8380878\tbest: 0.8380914 (4499)\ttotal: 4m 10s\tremaining: 3m 14s\n",
      "4750:\ttest: 0.8383477\tbest: 0.8383527 (4749)\ttotal: 4m 23s\tremaining: 3m\n",
      "5000:\ttest: 0.8384777\tbest: 0.8384962 (4987)\ttotal: 4m 37s\tremaining: 2m 46s\n",
      "5250:\ttest: 0.8386143\tbest: 0.8386368 (5239)\ttotal: 4m 51s\tremaining: 2m 32s\n",
      "5500:\ttest: 0.8386956\tbest: 0.8387165 (5466)\ttotal: 5m 5s\tremaining: 2m 18s\n",
      "5750:\ttest: 0.8387068\tbest: 0.8387423 (5699)\ttotal: 5m 19s\tremaining: 2m 4s\n",
      "6000:\ttest: 0.8387410\tbest: 0.8387835 (5929)\ttotal: 5m 33s\tremaining: 1m 50s\n",
      "6250:\ttest: 0.8388304\tbest: 0.8388413 (6231)\ttotal: 5m 47s\tremaining: 1m 37s\n",
      "6500:\ttest: 0.8389599\tbest: 0.8389663 (6496)\ttotal: 6m 1s\tremaining: 1m 23s\n",
      "6750:\ttest: 0.8390190\tbest: 0.8390254 (6749)\ttotal: 6m 14s\tremaining: 1m 9s\n",
      "7000:\ttest: 0.8391485\tbest: 0.8391492 (6979)\ttotal: 6m 28s\tremaining: 55.4s\n",
      "7250:\ttest: 0.8391530\tbest: 0.8391707 (7218)\ttotal: 6m 42s\tremaining: 41.6s\n",
      "7500:\ttest: 0.8391990\tbest: 0.8392061 (7350)\ttotal: 6m 56s\tremaining: 27.7s\n",
      "7750:\ttest: 0.8392626\tbest: 0.8392762 (7734)\ttotal: 7m 10s\tremaining: 13.8s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.8392762329\n",
      "bestIteration = 7734\n",
      "\n",
      "Shrink model to first 7735 iterations.\n",
      "\n",
      "Testing scores 0.839276232861032\n",
      "\n",
      "Training scores 0.8978341950780087\n",
      "========================Fold8==========================\n",
      "0:\ttest: 0.7927206\tbest: 0.7927206 (0)\ttotal: 110ms\tremaining: 14m 41s\n",
      "250:\ttest: 0.8220529\tbest: 0.8220537 (249)\ttotal: 17.1s\tremaining: 8m 48s\n",
      "500:\ttest: 0.8262220\tbest: 0.8262220 (500)\ttotal: 31.2s\tremaining: 7m 46s\n",
      "750:\ttest: 0.8282748\tbest: 0.8282748 (750)\ttotal: 45.1s\tremaining: 7m 14s\n",
      "1000:\ttest: 0.8300136\tbest: 0.8300136 (1000)\ttotal: 58.9s\tremaining: 6m 51s\n",
      "1250:\ttest: 0.8310998\tbest: 0.8310998 (1250)\ttotal: 1m 12s\tremaining: 6m 29s\n",
      "1500:\ttest: 0.8318692\tbest: 0.8318692 (1500)\ttotal: 1m 26s\tremaining: 6m 12s\n",
      "1750:\ttest: 0.8326322\tbest: 0.8326373 (1749)\ttotal: 1m 40s\tremaining: 5m 57s\n",
      "2000:\ttest: 0.8330068\tbest: 0.8330068 (2000)\ttotal: 1m 53s\tremaining: 5m 41s\n",
      "2250:\ttest: 0.8335448\tbest: 0.8335448 (2250)\ttotal: 2m 7s\tremaining: 5m 26s\n",
      "2500:\ttest: 0.8338108\tbest: 0.8338108 (2500)\ttotal: 2m 21s\tremaining: 5m 11s\n",
      "2750:\ttest: 0.8340425\tbest: 0.8340485 (2746)\ttotal: 2m 35s\tremaining: 4m 57s\n",
      "3000:\ttest: 0.8342180\tbest: 0.8342180 (3000)\ttotal: 2m 49s\tremaining: 4m 42s\n",
      "3250:\ttest: 0.8343904\tbest: 0.8343983 (3207)\ttotal: 3m 3s\tremaining: 4m 27s\n",
      "3500:\ttest: 0.8344931\tbest: 0.8345067 (3476)\ttotal: 3m 17s\tremaining: 4m 13s\n",
      "3750:\ttest: 0.8346231\tbest: 0.8346240 (3743)\ttotal: 3m 31s\tremaining: 3m 59s\n",
      "4000:\ttest: 0.8347505\tbest: 0.8347545 (3973)\ttotal: 3m 45s\tremaining: 3m 45s\n",
      "4250:\ttest: 0.8348212\tbest: 0.8348303 (4231)\ttotal: 3m 59s\tremaining: 3m 31s\n",
      "4500:\ttest: 0.8349289\tbest: 0.8349536 (4445)\ttotal: 4m 13s\tremaining: 3m 17s\n",
      "4750:\ttest: 0.8349632\tbest: 0.8349896 (4740)\ttotal: 4m 27s\tremaining: 3m 2s\n",
      "5000:\ttest: 0.8349851\tbest: 0.8350130 (4852)\ttotal: 4m 41s\tremaining: 2m 48s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.8350147634\n",
      "bestIteration = 5019\n",
      "\n",
      "Shrink model to first 5020 iterations.\n",
      "\n",
      "Testing scores 0.835014763440178\n",
      "\n",
      "Training scores 0.8809252903436711\n",
      "========================Fold9==========================\n",
      "0:\ttest: 0.7942406\tbest: 0.7942406 (0)\ttotal: 139ms\tremaining: 18m 33s\n",
      "250:\ttest: 0.8312861\tbest: 0.8312876 (249)\ttotal: 16.1s\tremaining: 8m 18s\n",
      "500:\ttest: 0.8355921\tbest: 0.8355921 (500)\ttotal: 30.1s\tremaining: 7m 29s\n",
      "750:\ttest: 0.8378566\tbest: 0.8378566 (750)\ttotal: 44s\tremaining: 7m 5s\n",
      "1000:\ttest: 0.8391819\tbest: 0.8391819 (1000)\ttotal: 57.9s\tremaining: 6m 44s\n",
      "1250:\ttest: 0.8400454\tbest: 0.8400454 (1250)\ttotal: 1m 11s\tremaining: 6m 27s\n",
      "1500:\ttest: 0.8405578\tbest: 0.8405578 (1500)\ttotal: 1m 25s\tremaining: 6m 11s\n",
      "1750:\ttest: 0.8409900\tbest: 0.8409900 (1750)\ttotal: 1m 39s\tremaining: 5m 55s\n",
      "2000:\ttest: 0.8414551\tbest: 0.8414580 (1999)\ttotal: 1m 53s\tremaining: 5m 39s\n",
      "2250:\ttest: 0.8417719\tbest: 0.8417719 (2250)\ttotal: 2m 6s\tremaining: 5m 23s\n",
      "2500:\ttest: 0.8419757\tbest: 0.8419929 (2469)\ttotal: 2m 20s\tremaining: 5m 9s\n",
      "2750:\ttest: 0.8421924\tbest: 0.8422110 (2726)\ttotal: 2m 34s\tremaining: 4m 54s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.8422335754\n",
      "bestIteration = 2788\n",
      "\n",
      "Shrink model to first 2789 iterations.\n",
      "\n",
      "Testing scores 0.8422335754142176\n",
      "\n",
      "Training scores 0.8634474445071565\n",
      "========================Fold10==========================\n",
      "0:\ttest: 0.7996771\tbest: 0.7996771 (0)\ttotal: 118ms\tremaining: 15m 40s\n",
      "250:\ttest: 0.8311276\tbest: 0.8311276 (250)\ttotal: 16.6s\tremaining: 8m 31s\n",
      "500:\ttest: 0.8358964\tbest: 0.8358964 (500)\ttotal: 30.5s\tremaining: 7m 37s\n",
      "750:\ttest: 0.8382991\tbest: 0.8383046 (749)\ttotal: 44.3s\tremaining: 7m 7s\n",
      "1000:\ttest: 0.8400730\tbest: 0.8400735 (999)\ttotal: 58s\tremaining: 6m 45s\n",
      "1250:\ttest: 0.8410496\tbest: 0.8410629 (1244)\ttotal: 1m 11s\tremaining: 6m 27s\n",
      "1500:\ttest: 0.8417169\tbest: 0.8417181 (1493)\ttotal: 1m 25s\tremaining: 6m 9s\n",
      "1750:\ttest: 0.8425566\tbest: 0.8425566 (1748)\ttotal: 1m 38s\tremaining: 5m 52s\n",
      "2000:\ttest: 0.8430741\tbest: 0.8430766 (1999)\ttotal: 1m 52s\tremaining: 5m 38s\n",
      "2250:\ttest: 0.8433508\tbest: 0.8433700 (2244)\ttotal: 2m 6s\tremaining: 5m 22s\n",
      "2500:\ttest: 0.8437347\tbest: 0.8437509 (2496)\ttotal: 2m 20s\tremaining: 5m 8s\n",
      "2750:\ttest: 0.8439678\tbest: 0.8439701 (2736)\ttotal: 2m 33s\tremaining: 4m 53s\n",
      "3000:\ttest: 0.8440947\tbest: 0.8441035 (2963)\ttotal: 2m 47s\tremaining: 4m 39s\n",
      "3250:\ttest: 0.8443934\tbest: 0.8443993 (3248)\ttotal: 3m 1s\tremaining: 4m 24s\n",
      "3500:\ttest: 0.8446127\tbest: 0.8446127 (3500)\ttotal: 3m 14s\tremaining: 4m 10s\n",
      "3750:\ttest: 0.8448529\tbest: 0.8448604 (3744)\ttotal: 3m 28s\tremaining: 3m 56s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000:\ttest: 0.8448827\tbest: 0.8449165 (3938)\ttotal: 3m 42s\tremaining: 3m 42s\n",
      "4250:\ttest: 0.8448484\tbest: 0.8449179 (4099)\ttotal: 3m 56s\tremaining: 3m 28s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.8449178529\n",
      "bestIteration = 4099\n",
      "\n",
      "Shrink model to first 4100 iterations.\n",
      "\n",
      "Testing scores 0.8449178529365524\n",
      "\n",
      "Training scores 0.8738885961450419\n",
      "Average Testing ROC score for 10 folds split: 0.8416457232003705\n",
      "Average Training ROC score for 10 folds split: 0.8751757480026956\n",
      "standard Deviation for 10 folds split: 0.004604869898856821\n"
     ]
    }
   ],
   "source": [
    "catboost2 =  CatBoostClassifier(random_seed=34,bootstrap_type='Bayesian',max_depth=6,learning_rate=0.007,\n",
    "                          iterations=8000,silent=True,eval_metric='AUC')\n",
    "\n",
    "\n",
    "cat2_train, cat2_test, cat2_name = cat_predict(catboost2,train, target, test,  'catboost(2)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL 4 : LIGHTGBM(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================Fold1==========================\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[250]\tvalid_0's auc: 0.827581\n",
      "[500]\tvalid_0's auc: 0.83103\n",
      "[750]\tvalid_0's auc: 0.833122\n",
      "[1000]\tvalid_0's auc: 0.834475\n",
      "[1250]\tvalid_0's auc: 0.835164\n",
      "[1500]\tvalid_0's auc: 0.835381\n",
      "Early stopping, best iteration is:\n",
      "[1444]\tvalid_0's auc: 0.835439\n",
      "\n",
      "Validation scores 0.8354386431501155\n",
      "\n",
      "Training scores 0.8697380048857971\n",
      "========================Fold2==========================\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[250]\tvalid_0's auc: 0.829749\n",
      "[500]\tvalid_0's auc: 0.833681\n",
      "[750]\tvalid_0's auc: 0.835792\n",
      "[1000]\tvalid_0's auc: 0.837001\n",
      "[1250]\tvalid_0's auc: 0.83729\n",
      "[1500]\tvalid_0's auc: 0.837399\n",
      "Early stopping, best iteration is:\n",
      "[1304]\tvalid_0's auc: 0.837473\n",
      "\n",
      "Validation scores 0.8374731521902794\n",
      "\n",
      "Training scores 0.8667644901241149\n",
      "========================Fold3==========================\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[250]\tvalid_0's auc: 0.829795\n",
      "[500]\tvalid_0's auc: 0.835612\n",
      "[750]\tvalid_0's auc: 0.838497\n",
      "[1000]\tvalid_0's auc: 0.84054\n",
      "[1250]\tvalid_0's auc: 0.841581\n",
      "[1500]\tvalid_0's auc: 0.842067\n",
      "[1750]\tvalid_0's auc: 0.842314\n",
      "[2000]\tvalid_0's auc: 0.842412\n",
      "[2250]\tvalid_0's auc: 0.8421\n",
      "Early stopping, best iteration is:\n",
      "[2116]\tvalid_0's auc: 0.84249\n",
      "\n",
      "Validation scores 0.8424899175727183\n",
      "\n",
      "Training scores 0.8802799701255482\n",
      "========================Fold4==========================\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[250]\tvalid_0's auc: 0.837913\n",
      "[500]\tvalid_0's auc: 0.843035\n",
      "[750]\tvalid_0's auc: 0.845513\n",
      "[1000]\tvalid_0's auc: 0.847367\n",
      "[1250]\tvalid_0's auc: 0.848076\n",
      "[1500]\tvalid_0's auc: 0.848366\n",
      "[1750]\tvalid_0's auc: 0.848637\n",
      "[2000]\tvalid_0's auc: 0.84877\n",
      "Early stopping, best iteration is:\n",
      "[1979]\tvalid_0's auc: 0.848819\n",
      "\n",
      "Validation scores 0.8488192137957513\n",
      "\n",
      "Training scores 0.8772835470165671\n",
      "========================Fold5==========================\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[250]\tvalid_0's auc: 0.829858\n",
      "[500]\tvalid_0's auc: 0.835076\n",
      "[750]\tvalid_0's auc: 0.838249\n",
      "[1000]\tvalid_0's auc: 0.839947\n",
      "[1250]\tvalid_0's auc: 0.840566\n",
      "[1500]\tvalid_0's auc: 0.841153\n",
      "[1750]\tvalid_0's auc: 0.841282\n",
      "Early stopping, best iteration is:\n",
      "[1647]\tvalid_0's auc: 0.841358\n",
      "\n",
      "Validation scores 0.841358139993746\n",
      "\n",
      "Training scores 0.8719843459279097\n",
      "========================Fold6==========================\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[250]\tvalid_0's auc: 0.83852\n",
      "[500]\tvalid_0's auc: 0.842864\n",
      "[750]\tvalid_0's auc: 0.844933\n",
      "[1000]\tvalid_0's auc: 0.845966\n",
      "[1250]\tvalid_0's auc: 0.846512\n",
      "[1500]\tvalid_0's auc: 0.846775\n",
      "Early stopping, best iteration is:\n",
      "[1428]\tvalid_0's auc: 0.846886\n",
      "\n",
      "Validation scores 0.846885851921523\n",
      "\n",
      "Training scores 0.8682192803870603\n",
      "========================Fold7==========================\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[250]\tvalid_0's auc: 0.820342\n",
      "[500]\tvalid_0's auc: 0.827326\n",
      "[750]\tvalid_0's auc: 0.831379\n",
      "[1000]\tvalid_0's auc: 0.833731\n",
      "[1250]\tvalid_0's auc: 0.835073\n",
      "[1500]\tvalid_0's auc: 0.836147\n",
      "[1750]\tvalid_0's auc: 0.836942\n",
      "[2000]\tvalid_0's auc: 0.837387\n",
      "[2250]\tvalid_0's auc: 0.837785\n",
      "[2500]\tvalid_0's auc: 0.837822\n",
      "[2750]\tvalid_0's auc: 0.838079\n",
      "Early stopping, best iteration is:\n",
      "[2621]\tvalid_0's auc: 0.838144\n",
      "\n",
      "Validation scores 0.8381444955330422\n",
      "\n",
      "Training scores 0.8875201484583888\n",
      "========================Fold8==========================\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[250]\tvalid_0's auc: 0.823445\n",
      "[500]\tvalid_0's auc: 0.828252\n",
      "[750]\tvalid_0's auc: 0.831021\n",
      "[1000]\tvalid_0's auc: 0.832355\n",
      "[1250]\tvalid_0's auc: 0.833318\n",
      "[1500]\tvalid_0's auc: 0.833852\n",
      "[1750]\tvalid_0's auc: 0.833944\n",
      "Early stopping, best iteration is:\n",
      "[1595]\tvalid_0's auc: 0.834009\n",
      "\n",
      "Validation scores 0.8340086980866139\n",
      "\n",
      "Training scores 0.8721820570397618\n",
      "========================Fold9==========================\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[250]\tvalid_0's auc: 0.831714\n",
      "[500]\tvalid_0's auc: 0.83679\n",
      "[750]\tvalid_0's auc: 0.839232\n",
      "[1000]\tvalid_0's auc: 0.840304\n",
      "[1250]\tvalid_0's auc: 0.840711\n",
      "[1500]\tvalid_0's auc: 0.841083\n",
      "[1750]\tvalid_0's auc: 0.841465\n",
      "[2000]\tvalid_0's auc: 0.841425\n",
      "Early stopping, best iteration is:\n",
      "[1840]\tvalid_0's auc: 0.841547\n",
      "\n",
      "Validation scores 0.8415466030985985\n",
      "\n",
      "Training scores 0.8755863718461802\n",
      "========================Fold10==========================\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[250]\tvalid_0's auc: 0.833003\n",
      "[500]\tvalid_0's auc: 0.838883\n",
      "[750]\tvalid_0's auc: 0.841757\n",
      "[1000]\tvalid_0's auc: 0.84321\n",
      "[1250]\tvalid_0's auc: 0.843985\n",
      "[1500]\tvalid_0's auc: 0.844445\n",
      "[1750]\tvalid_0's auc: 0.844843\n",
      "[2000]\tvalid_0's auc: 0.844935\n",
      "[2250]\tvalid_0's auc: 0.844991\n",
      "Early stopping, best iteration is:\n",
      "[2244]\tvalid_0's auc: 0.845027\n",
      "\n",
      "Validation scores 0.8450273202942482\n",
      "\n",
      "Training scores 0.8817979851050912\n",
      "Average Testing ROC score for 10 folds split: 0.8411192035636637\n",
      "Average Training ROC score for 10 folds split: 0.8751356200916419\n",
      "standard Deviation for 10 folds split: 0.004635806492380356\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lgb_model2 = lgbm.LGBMClassifier(random_state=34, n_estimators=5000,colsample_bytree=0.9,min_child_samples=10,\n",
    "    subsample=0.5,subsample_freq=2,num_leaves=120,reg_lambda=2,reg_alpha=5 ,metric='auc', learning_rate=0.008,\n",
    "    max_depth=5)\n",
    "LGBM2_train, LGBM2_test, LGBM2_name= lgb_predict(lgb_model2,train, target, test,  'lightgbm(2)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL 5: RANDOM FORESTS(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================Fold1==========================\n",
      "\n",
      "Validation scores 0.8308597904883426\n",
      "\n",
      "Training scores 0.9994967550293589\n",
      "========================Fold2==========================\n",
      "\n",
      "Validation scores 0.8326266191257993\n",
      "\n",
      "Training scores 0.9995233237309932\n",
      "========================Fold3==========================\n",
      "\n",
      "Validation scores 0.8340319412400122\n",
      "\n",
      "Training scores 0.9995151579157964\n",
      "========================Fold4==========================\n",
      "\n",
      "Validation scores 0.8437676085670837\n",
      "\n",
      "Training scores 0.9994997065160038\n",
      "========================Fold5==========================\n",
      "\n",
      "Validation scores 0.8345896374914001\n",
      "\n",
      "Training scores 0.9995359130508766\n",
      "========================Fold6==========================\n",
      "\n",
      "Validation scores 0.8431613759167675\n",
      "\n",
      "Training scores 0.9995114825299543\n",
      "========================Fold7==========================\n",
      "\n",
      "Validation scores 0.8312485691668207\n",
      "\n",
      "Training scores 0.9994986668630205\n",
      "========================Fold8==========================\n",
      "\n",
      "Validation scores 0.8312311578233131\n",
      "\n",
      "Training scores 0.9995244567960886\n",
      "========================Fold9==========================\n",
      "\n",
      "Validation scores 0.8386589059194431\n",
      "\n",
      "Training scores 0.9995185524352512\n",
      "========================Fold10==========================\n",
      "\n",
      "Validation scores 0.8399642395138889\n",
      "\n",
      "Training scores 0.999486621839181\n",
      "Average Testing ROC score for 10 folds split: 0.8360139845252871\n",
      "Average Training ROC score for 10 folds split: 0.9995110636706525\n",
      "standard Deviation for 10 folds split: 0.004726371213926837\n"
     ]
    }
   ],
   "source": [
    "rf1_model = RandomForestClassifier(n_jobs=-1,criterion='entropy',min_samples_split=10,n_estimators=400,random_state=99)\n",
    "rf1_train, rf1_test, rf1_name = model_predict(rf1_model,train, target, test, 'RandomForest(1)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL 6: RANDOM FORESTS(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================Fold1==========================\n",
      "\n",
      "Validation scores 0.8287061015781587\n",
      "\n",
      "Training scores 0.879419820916435\n",
      "========================Fold2==========================\n",
      "\n",
      "Validation scores 0.8308459925294401\n",
      "\n",
      "Training scores 0.8793232573843832\n",
      "========================Fold3==========================\n",
      "\n",
      "Validation scores 0.8320115751077233\n",
      "\n",
      "Training scores 0.8788761619725123\n",
      "========================Fold4==========================\n",
      "\n",
      "Validation scores 0.8400288791279827\n",
      "\n",
      "Training scores 0.8782773667461575\n",
      "========================Fold5==========================\n",
      "\n",
      "Validation scores 0.8311167774729002\n",
      "\n",
      "Training scores 0.8787436516108675\n",
      "========================Fold6==========================\n",
      "\n",
      "Validation scores 0.8402940207032941\n",
      "\n",
      "Training scores 0.8783288277074531\n",
      "========================Fold7==========================\n",
      "\n",
      "Validation scores 0.8238815021886574\n",
      "\n",
      "Training scores 0.8788595410802063\n",
      "========================Fold8==========================\n",
      "\n",
      "Validation scores 0.8268524635154778\n",
      "\n",
      "Training scores 0.8790923317092868\n",
      "========================Fold9==========================\n",
      "\n",
      "Validation scores 0.8356638100570678\n",
      "\n",
      "Training scores 0.8784382217720549\n",
      "========================Fold10==========================\n",
      "\n",
      "Validation scores 0.8366829770156475\n",
      "\n",
      "Training scores 0.8784801238936932\n",
      "Average Testing ROC score for 10 folds split: 0.8326084099296349\n",
      "Average Training ROC score for 10 folds split: 0.8787839304793049\n",
      "standard Deviation for 10 folds split: 0.005198794913826382\n"
     ]
    }
   ],
   "source": [
    "rf_model2 = RandomForestClassifier(max_depth=10,min_samples_split=10,min_samples_leaf=15,n_estimators=400,n_jobs=-1,random_state=34)\n",
    "rf2_train, rf2_test, rf2_name= model_predict( rf_model2,train, target, test, 'RandomForest(2)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL 7: XGBOOST(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================Fold1==========================\n",
      "[0]\tvalidation_0-auc:0.78424\n",
      "Will train until validation_0-auc hasn't improved in 200 rounds.\n",
      "[250]\tvalidation_0-auc:0.82764\n",
      "[500]\tvalidation_0-auc:0.83101\n",
      "[750]\tvalidation_0-auc:0.83296\n",
      "[1000]\tvalidation_0-auc:0.83402\n",
      "[1250]\tvalidation_0-auc:0.83466\n",
      "[1500]\tvalidation_0-auc:0.83475\n",
      "[1750]\tvalidation_0-auc:0.83473\n",
      "Stopping. Best iteration:\n",
      "[1689]\tvalidation_0-auc:0.83483\n",
      "\n",
      "\n",
      "Testing scores 0.8348318779073809\n",
      "\n",
      "Training scores 0.8765534143597913\n",
      "========================Fold2==========================\n",
      "[0]\tvalidation_0-auc:0.78883\n",
      "Will train until validation_0-auc hasn't improved in 200 rounds.\n",
      "[250]\tvalidation_0-auc:0.82926\n",
      "[500]\tvalidation_0-auc:0.83372\n",
      "[750]\tvalidation_0-auc:0.83592\n",
      "[1000]\tvalidation_0-auc:0.83677\n",
      "[1250]\tvalidation_0-auc:0.83720\n",
      "[1500]\tvalidation_0-auc:0.83733\n",
      "[1750]\tvalidation_0-auc:0.83736\n",
      "Stopping. Best iteration:\n",
      "[1589]\tvalidation_0-auc:0.83748\n",
      "\n",
      "\n",
      "Testing scores 0.8374760842565462\n",
      "\n",
      "Training scores 0.8745505821417316\n",
      "========================Fold3==========================\n",
      "[0]\tvalidation_0-auc:0.79230\n",
      "Will train until validation_0-auc hasn't improved in 200 rounds.\n",
      "[250]\tvalidation_0-auc:0.83034\n",
      "[500]\tvalidation_0-auc:0.83597\n",
      "[750]\tvalidation_0-auc:0.83937\n",
      "[1000]\tvalidation_0-auc:0.84099\n",
      "[1250]\tvalidation_0-auc:0.84181\n",
      "[1500]\tvalidation_0-auc:0.84222\n",
      "[1750]\tvalidation_0-auc:0.84215\n",
      "Stopping. Best iteration:\n",
      "[1608]\tvalidation_0-auc:0.84236\n",
      "\n",
      "\n",
      "Testing scores 0.8423614240804393\n",
      "\n",
      "Training scores 0.8744562431344143\n",
      "========================Fold4==========================\n",
      "[0]\tvalidation_0-auc:0.80616\n",
      "Will train until validation_0-auc hasn't improved in 200 rounds.\n",
      "[250]\tvalidation_0-auc:0.83786\n",
      "[500]\tvalidation_0-auc:0.84293\n",
      "[750]\tvalidation_0-auc:0.84555\n",
      "[1000]\tvalidation_0-auc:0.84675\n",
      "[1250]\tvalidation_0-auc:0.84749\n",
      "[1500]\tvalidation_0-auc:0.84769\n",
      "[1750]\tvalidation_0-auc:0.84785\n",
      "[2000]\tvalidation_0-auc:0.84781\n",
      "Stopping. Best iteration:\n",
      "[1957]\tvalidation_0-auc:0.84792\n",
      "\n",
      "\n",
      "Testing scores 0.8479166548090458\n",
      "\n",
      "Training scores 0.8797538615109759\n",
      "========================Fold5==========================\n",
      "[0]\tvalidation_0-auc:0.79875\n",
      "Will train until validation_0-auc hasn't improved in 200 rounds.\n",
      "[250]\tvalidation_0-auc:0.83012\n",
      "[500]\tvalidation_0-auc:0.83527\n",
      "[750]\tvalidation_0-auc:0.83870\n",
      "[1000]\tvalidation_0-auc:0.84024\n",
      "[1250]\tvalidation_0-auc:0.84097\n",
      "[1500]\tvalidation_0-auc:0.84118\n",
      "Stopping. Best iteration:\n",
      "[1399]\tvalidation_0-auc:0.84122\n",
      "\n",
      "\n",
      "Testing scores 0.841219729218506\n",
      "\n",
      "Training scores 0.8704535344424037\n",
      "========================Fold6==========================\n",
      "[0]\tvalidation_0-auc:0.79740\n",
      "Will train until validation_0-auc hasn't improved in 200 rounds.\n",
      "[250]\tvalidation_0-auc:0.83930\n",
      "[500]\tvalidation_0-auc:0.84353\n",
      "[750]\tvalidation_0-auc:0.84537\n",
      "[1000]\tvalidation_0-auc:0.84639\n",
      "[1250]\tvalidation_0-auc:0.84680\n",
      "[1500]\tvalidation_0-auc:0.84682\n",
      "[1750]\tvalidation_0-auc:0.84693\n",
      "[2000]\tvalidation_0-auc:0.84671\n",
      "Stopping. Best iteration:\n",
      "[1851]\tvalidation_0-auc:0.84699\n",
      "\n",
      "\n",
      "Testing scores 0.8469901475930283\n",
      "\n",
      "Training scores 0.8784984554066447\n",
      "========================Fold7==========================\n",
      "[0]\tvalidation_0-auc:0.78290\n",
      "Will train until validation_0-auc hasn't improved in 200 rounds.\n",
      "[250]\tvalidation_0-auc:0.82174\n",
      "[500]\tvalidation_0-auc:0.82855\n",
      "[750]\tvalidation_0-auc:0.83255\n",
      "[1000]\tvalidation_0-auc:0.83468\n",
      "[1250]\tvalidation_0-auc:0.83594\n",
      "[1500]\tvalidation_0-auc:0.83673\n",
      "[1750]\tvalidation_0-auc:0.83731\n",
      "[2000]\tvalidation_0-auc:0.83775\n",
      "[2250]\tvalidation_0-auc:0.83799\n",
      "[2500]\tvalidation_0-auc:0.83815\n",
      "[2750]\tvalidation_0-auc:0.83845\n",
      "[3000]\tvalidation_0-auc:0.83846\n",
      "Stopping. Best iteration:\n",
      "[2827]\tvalidation_0-auc:0.83856\n",
      "\n",
      "\n",
      "Testing scores 0.8385565927276438\n",
      "\n",
      "Training scores 0.8936440531661903\n",
      "========================Fold8==========================\n",
      "[0]\tvalidation_0-auc:0.79148\n",
      "Will train until validation_0-auc hasn't improved in 200 rounds.\n",
      "[250]\tvalidation_0-auc:0.82384\n",
      "[500]\tvalidation_0-auc:0.82859\n",
      "[750]\tvalidation_0-auc:0.83173\n",
      "[1000]\tvalidation_0-auc:0.83310\n",
      "[1250]\tvalidation_0-auc:0.83385\n",
      "[1500]\tvalidation_0-auc:0.83425\n",
      "[1750]\tvalidation_0-auc:0.83448\n",
      "[2000]\tvalidation_0-auc:0.83444\n",
      "[2250]\tvalidation_0-auc:0.83448\n",
      "Stopping. Best iteration:\n",
      "[2297]\tvalidation_0-auc:0.83454\n",
      "\n",
      "\n",
      "Testing scores 0.8345381063629669\n",
      "\n",
      "Training scores 0.8861050220785945\n",
      "========================Fold9==========================\n",
      "[0]\tvalidation_0-auc:0.79511\n",
      "Will train until validation_0-auc hasn't improved in 200 rounds.\n",
      "[250]\tvalidation_0-auc:0.83124\n",
      "[500]\tvalidation_0-auc:0.83675\n",
      "[750]\tvalidation_0-auc:0.83951\n",
      "[1000]\tvalidation_0-auc:0.84078\n",
      "[1250]\tvalidation_0-auc:0.84142\n",
      "[1500]\tvalidation_0-auc:0.84176\n",
      "[1750]\tvalidation_0-auc:0.84173\n",
      "Stopping. Best iteration:\n",
      "[1712]\tvalidation_0-auc:0.84178\n",
      "\n",
      "\n",
      "Testing scores 0.8417832939365771\n",
      "\n",
      "Training scores 0.8762405222315302\n",
      "========================Fold10==========================\n",
      "[0]\tvalidation_0-auc:0.79854\n",
      "Will train until validation_0-auc hasn't improved in 200 rounds.\n",
      "[250]\tvalidation_0-auc:0.83356\n",
      "[500]\tvalidation_0-auc:0.83921\n",
      "[750]\tvalidation_0-auc:0.84216\n",
      "[1000]\tvalidation_0-auc:0.84362\n",
      "[1250]\tvalidation_0-auc:0.84439\n",
      "[1500]\tvalidation_0-auc:0.84473\n",
      "[1750]\tvalidation_0-auc:0.84484\n",
      "[2000]\tvalidation_0-auc:0.84492\n",
      "Stopping. Best iteration:\n",
      "[1881]\tvalidation_0-auc:0.84495\n",
      "\n",
      "\n",
      "Testing scores 0.8449535375712657\n",
      "\n",
      "Training scores 0.8790165415155409\n",
      "Average Testing ROC score for 10 folds split: 0.8410627448463399\n",
      "Average Training ROC score for 10 folds split: 0.8789272229987818\n",
      "standard Deviation for 10 folds split: 0.004472341654462893\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "Xgboost = XGBClassifier(learning_rate=0.01,subsample=0.7,colsample_bytree=0.9,reg_alpha=10,\n",
    "               n_jobs=-1,n_estimators=5000,max_depth= 5,random_state=34)\n",
    "\n",
    "xgb_train, xgb_test, xgb_name= xgb_predict(Xgboost,train, target, test,'xgboost')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL 8: GRADIENT BOOSTING MACHINES.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================Fold1==========================\n",
      "\n",
      "Validation scores 0.8330371084031468\n",
      "\n",
      "Training scores 0.8707550341782366\n",
      "========================Fold2==========================\n",
      "\n",
      "Validation scores 0.8353472316723869\n",
      "\n",
      "Training scores 0.8712694390253557\n",
      "========================Fold3==========================\n",
      "\n",
      "Validation scores 0.8405669132879346\n",
      "\n",
      "Training scores 0.8695435069184125\n",
      "========================Fold4==========================\n",
      "\n",
      "Validation scores 0.8462846149826173\n",
      "\n",
      "Training scores 0.8696511409202062\n",
      "========================Fold5==========================\n",
      "\n",
      "Validation scores 0.8387300600090479\n",
      "\n",
      "Training scores 0.8703997754494486\n",
      "========================Fold6==========================\n",
      "\n",
      "Validation scores 0.8454707923850714\n",
      "\n",
      "Training scores 0.8704792295815413\n",
      "========================Fold7==========================\n",
      "\n",
      "Validation scores 0.8329771190811774\n",
      "\n",
      "Training scores 0.8706396925886813\n",
      "========================Fold8==========================\n",
      "\n",
      "Validation scores 0.8313357120791283\n",
      "\n",
      "Training scores 0.87116135303392\n",
      "========================Fold9==========================\n",
      "\n",
      "Validation scores 0.8397406502809258\n",
      "\n",
      "Training scores 0.8700812169048839\n",
      "========================Fold10==========================\n",
      "\n",
      "Validation scores 0.8421521213567195\n",
      "\n",
      "Training scores 0.8693762530387953\n",
      "Average Testing ROC score for 10 folds split: 0.8385642323538157\n",
      "Average Training ROC score for 10 folds split: 0.8703356641639483\n",
      "standard Deviation for 10 folds split: 0.004999655472181822\n"
     ]
    }
   ],
   "source": [
    "gbm_model = GradientBoostingClassifier(max_depth=4,min_samples_leaf=10,n_estimators=200,learning_rate=0.1,min_samples_split=10,random_state=10)\n",
    "gbm_train, gbm_test, gbm_name= model_predict(gbm_model,train, target, test, 'Gbm')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STACKING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Stacking is an ensemble learning technique that combines multiple classification or regression models via a meta-classifier or regressor.. Here the base level models are trained  on the training set via cross validation, and the meta model(LinearRegression) is then trained on the predictions of the base level models as features in order to fine tune our predictions...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>xgboost</th>\n",
       "      <th>RandomForest(1)</th>\n",
       "      <th>RandomForest(2)</th>\n",
       "      <th>lightgbm(1)</th>\n",
       "      <th>lightgbm(2)</th>\n",
       "      <th>catboost(1)</th>\n",
       "      <th>catboost(2)</th>\n",
       "      <th>Gbm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.300142</td>\n",
       "      <td>0.350402</td>\n",
       "      <td>0.359993</td>\n",
       "      <td>0.299951</td>\n",
       "      <td>0.297754</td>\n",
       "      <td>0.316275</td>\n",
       "      <td>0.310177</td>\n",
       "      <td>0.353062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.337876</td>\n",
       "      <td>0.376003</td>\n",
       "      <td>0.381340</td>\n",
       "      <td>0.368442</td>\n",
       "      <td>0.362913</td>\n",
       "      <td>0.368979</td>\n",
       "      <td>0.364976</td>\n",
       "      <td>0.338744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.404822</td>\n",
       "      <td>0.392471</td>\n",
       "      <td>0.374665</td>\n",
       "      <td>0.403675</td>\n",
       "      <td>0.402645</td>\n",
       "      <td>0.392726</td>\n",
       "      <td>0.381531</td>\n",
       "      <td>0.414784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.765664</td>\n",
       "      <td>0.679308</td>\n",
       "      <td>0.639713</td>\n",
       "      <td>0.749910</td>\n",
       "      <td>0.755325</td>\n",
       "      <td>0.738753</td>\n",
       "      <td>0.740660</td>\n",
       "      <td>0.738248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.121092</td>\n",
       "      <td>0.214100</td>\n",
       "      <td>0.217011</td>\n",
       "      <td>0.120897</td>\n",
       "      <td>0.132331</td>\n",
       "      <td>0.176077</td>\n",
       "      <td>0.188173</td>\n",
       "      <td>0.190475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    xgboost  RandomForest(1)  RandomForest(2)  lightgbm(1)  lightgbm(2)  \\\n",
       "0  0.300142         0.350402         0.359993     0.299951     0.297754   \n",
       "1  0.337876         0.376003         0.381340     0.368442     0.362913   \n",
       "2  0.404822         0.392471         0.374665     0.403675     0.402645   \n",
       "3  0.765664         0.679308         0.639713     0.749910     0.755325   \n",
       "4  0.121092         0.214100         0.217011     0.120897     0.132331   \n",
       "\n",
       "   catboost(1)  catboost(2)       Gbm  \n",
       "0     0.316275     0.310177  0.353062  \n",
       "1     0.368979     0.364976  0.338744  \n",
       "2     0.392726     0.381531  0.414784  \n",
       "3     0.738753     0.740660  0.738248  \n",
       "4     0.176077     0.188173  0.190475  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "Train_stack3 = pd.DataFrame(xgb_train)\n",
    "Train_stack3 = pd.concat([Train_stack3,pd.DataFrame(rf1_train),pd.DataFrame(rf2_train),\n",
    "                        pd.DataFrame(LGB1__train),pd.DataFrame(LGBM2_train),pd.DataFrame(cat1_train),pd.DataFrame(cat2_train),\n",
    "                         pd.DataFrame(gbm_train)],1)\n",
    "Test_stack3 = pd.DataFrame(xgb_test)\n",
    "Test_stack3 = pd.concat([Test_stack3,pd.DataFrame(rf1_test),pd.DataFrame(rf2_test),\n",
    "                        pd.DataFrame(LGB1_test),pd.DataFrame(LGBM2_test),pd.DataFrame(cat1_test),pd.DataFrame(cat2_test),\n",
    "                        pd.DataFrame(gbm_test)],1)\n",
    "Test_stack3.columns=[xgb_name,rf1_name,rf2_name,LGB1_name,LGBM2_name,cat1_name,cat2_name,gbm_name]\n",
    "Train_stack3.columns=[xgb_name,rf1_name,rf2_name,LGB1_name,LGBM2_name,cat1_name,cat2_name,gbm_name]\n",
    "Test_stack3 = Test_stack3/10 #average predictions for 1o folds on the Test set..\n",
    "Test_stack3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_estimator = LinearRegression()\n",
    "Stack(meta_estimator,Train_stack3,Test_stack3,target,'omni_stack.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>xgboost</th>\n",
       "      <th>RandomForest(1)</th>\n",
       "      <th>RandomForest(2)</th>\n",
       "      <th>lightgbm(1)</th>\n",
       "      <th>lightgbm(2)</th>\n",
       "      <th>catboost(1)</th>\n",
       "      <th>catboost(2)</th>\n",
       "      <th>Gbm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>xgboost</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.968880</td>\n",
       "      <td>0.962674</td>\n",
       "      <td>0.997712</td>\n",
       "      <td>0.997265</td>\n",
       "      <td>0.987618</td>\n",
       "      <td>0.992022</td>\n",
       "      <td>0.986512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest(1)</th>\n",
       "      <td>0.968880</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.984621</td>\n",
       "      <td>0.970204</td>\n",
       "      <td>0.970905</td>\n",
       "      <td>0.965940</td>\n",
       "      <td>0.971328</td>\n",
       "      <td>0.961307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest(2)</th>\n",
       "      <td>0.962674</td>\n",
       "      <td>0.984621</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.965007</td>\n",
       "      <td>0.966236</td>\n",
       "      <td>0.961341</td>\n",
       "      <td>0.967778</td>\n",
       "      <td>0.958240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lightgbm(1)</th>\n",
       "      <td>0.997712</td>\n",
       "      <td>0.970204</td>\n",
       "      <td>0.965007</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997941</td>\n",
       "      <td>0.988750</td>\n",
       "      <td>0.993036</td>\n",
       "      <td>0.987702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lightgbm(2)</th>\n",
       "      <td>0.997265</td>\n",
       "      <td>0.970905</td>\n",
       "      <td>0.966236</td>\n",
       "      <td>0.997941</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.988544</td>\n",
       "      <td>0.993151</td>\n",
       "      <td>0.986610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>catboost(1)</th>\n",
       "      <td>0.987618</td>\n",
       "      <td>0.965940</td>\n",
       "      <td>0.961341</td>\n",
       "      <td>0.988750</td>\n",
       "      <td>0.988544</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.994138</td>\n",
       "      <td>0.983241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>catboost(2)</th>\n",
       "      <td>0.992022</td>\n",
       "      <td>0.971328</td>\n",
       "      <td>0.967778</td>\n",
       "      <td>0.993036</td>\n",
       "      <td>0.993151</td>\n",
       "      <td>0.994138</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.986557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gbm</th>\n",
       "      <td>0.986512</td>\n",
       "      <td>0.961307</td>\n",
       "      <td>0.958240</td>\n",
       "      <td>0.987702</td>\n",
       "      <td>0.986610</td>\n",
       "      <td>0.983241</td>\n",
       "      <td>0.986557</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  xgboost  RandomForest(1)  RandomForest(2)  lightgbm(1)  \\\n",
       "xgboost          1.000000         0.968880         0.962674     0.997712   \n",
       "RandomForest(1)  0.968880         1.000000         0.984621     0.970204   \n",
       "RandomForest(2)  0.962674         0.984621         1.000000     0.965007   \n",
       "lightgbm(1)      0.997712         0.970204         0.965007     1.000000   \n",
       "lightgbm(2)      0.997265         0.970905         0.966236     0.997941   \n",
       "catboost(1)      0.987618         0.965940         0.961341     0.988750   \n",
       "catboost(2)      0.992022         0.971328         0.967778     0.993036   \n",
       "Gbm              0.986512         0.961307         0.958240     0.987702   \n",
       "\n",
       "                 lightgbm(2)  catboost(1)  catboost(2)       Gbm  \n",
       "xgboost             0.997265     0.987618     0.992022  0.986512  \n",
       "RandomForest(1)     0.970905     0.965940     0.971328  0.961307  \n",
       "RandomForest(2)     0.966236     0.961341     0.967778  0.958240  \n",
       "lightgbm(1)         0.997941     0.988750     0.993036  0.987702  \n",
       "lightgbm(2)         1.000000     0.988544     0.993151  0.986610  \n",
       "catboost(1)         0.988544     1.000000     0.994138  0.983241  \n",
       "catboost(2)         0.993151     0.994138     1.000000  0.986557  \n",
       "Gbm                 0.986610     0.983241     0.986557  1.000000  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CORRELATION BETWEEN PREDICTIONS..\n",
    "Train_stack3.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Best Model Stack LB** :0.845389667355..\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FURTHER IMPROVEMENTS**\n",
    "*   I used have used One Hot Encoding instead as it does better than target encoding as target encoding tends to introduce noise into the encoding of the categorical variables(noise which were originally from the target variable itself) and as such can cause data leakages leading to overfitting and poor predictive performance...\n",
    "*   Feature engineering\n",
    "*   Outlier handling\n",
    "*   Train the different models on different random_seeds so as not to overfit a paticular seed\n",
    "*   Removing the different features that were detrimental to the individual model's performance.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
